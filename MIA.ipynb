{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff4919c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader \n",
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBoxRuleBased\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import lenet\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2f3df7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    '''\n",
    "    topk = 1이라면 가장 높은 예측 확률을 가진 레이블과 실제 레이블이 동일한지 계산 \n",
    "    topk = (1, 5)라면, 가장 높은 예측 확률을 가진 레이블과 실제 레이블이 동일한 경우를 계산하여\n",
    "    top1 정확도 구하고, 그 다음으로 높은 5개의 예측 확률을 가진 레이블 중 실제 레이블이 포함되는지 확인하여 top5 정확도 구함\n",
    "    \n",
    "    더욱 모델의 성능을 상세하게 평가하기 위한 방법으로, 모델의 성능을 다각도로 이해하고 평가하는 데 도움됨\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1b62d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = MNIST('/cache/data/',\n",
    "                       download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((32, 32)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ]))\n",
    "data_test = MNIST('/cache/data/',\n",
    "                download=True,\n",
    "                train=False,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "363fa48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data_train, batch_size=1024, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2415f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDD\\AppData\\Local\\Temp\\ipykernel_20504\\673115023.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distilled = torch.load(\"./DFKD_pths/LeNet5Half_MNIST_TestSet_distilled\")\n",
      "C:\\Users\\HDD\\AppData\\Local\\Temp\\ipykernel_20504\\673115023.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  synthetic = torch.load(\"./DFKD_pths/LeNet5Half_Synthetic_MNIST\")\n",
      "C:\\Users\\HDD\\AppData\\Local\\Temp\\ipykernel_20504\\673115023.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adv_synthetic = torch.load(\"./DFKD_pths/LeNet5Half_Synthetic_Adv_MNIST\")\n"
     ]
    }
   ],
   "source": [
    "distilled = torch.load(\"./DFKD_pths/LeNet5Half_MNIST_TestSet_distilled\")\n",
    "synthetic = torch.load(\"./DFKD_pths/LeNet5Half_Synthetic_MNIST\")\n",
    "adv_synthetic = torch.load(\"./DFKD_pths/LeNet5Half_Synthetic_Adv_MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3490a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc1 = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = images.size(0)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc1, _ = accuracy(outputs, labels, topk=(1, 5))\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_acc1 += acc1.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            \n",
    "    val_loss = total_loss / total_samples\n",
    "    val_acc1 = total_acc1 / total_samples\n",
    "    return val_loss, val_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "991f4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1537, Test Accuracy: 95.6867%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc1 = evaluate_model(distilled, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {val_loss:.4f}, Test Accuracy: {val_acc1 / 100:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e257a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2492, Test Accuracy: 92.68%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc1 = evaluate_model(synthetic, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {val_loss:.4f}, Test Accuracy: {val_acc1 / 100:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d1054e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3131, Test Accuracy: 92.02%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc1 = evaluate_model(adv_synthetic, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {val_loss:.4f}, Test Accuracy: {val_acc1 / 100:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8499dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(data_train, batch_size=1000, shuffle=True)\n",
    "x_train, y_train = next(iter(train_data_loader))\n",
    "\n",
    "test_data_loader = DataLoader(data_test, batch_size=500, shuffle=True)\n",
    "x_test, y_test = next(iter(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b7055697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_based_Attack(model, batch_size=1000):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    x_member = x_train[:batch_size]\n",
    "    y_member = y_train[:batch_size]\n",
    "    x_nonmember = x_test[:(batch_size // 2)]\n",
    "    y_nonmember = y_test[:(batch_size // 2)]\n",
    "\n",
    "    x_target = np.concatenate([x_member, x_nonmember], axis=0)\n",
    "    y_target = np.concatenate([y_member, y_nonmember], axis=0)\n",
    "    \n",
    "    x_tensor = torch.from_numpy(x_target).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_tensor)\n",
    "        pred_labels = logits.argmax(dim=1).cpu().numpy()\n",
    "    \n",
    "    predictions = (pred_labels == y_target).astype(np.int32)\n",
    "\n",
    "    true_membership = np.array([1] * batch_size + [0] * (batch_size // 2))\n",
    "    \n",
    "    MIA_ACC = (predictions == true_membership).mean()\n",
    "    return MIA_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6f60cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6446666666666667\n",
      "0.6333333333333333\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "print(Rule_based_Attack(distilled))\n",
    "print(Rule_based_Attack(synthetic))\n",
    "print(Rule_based_Attack(adv_synthetic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "a19cc3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conf_Rule_based_Attack(model, batch_size=1000):\n",
    "    \n",
    "    model.eval()\n",
    "    threshold = 0.98\n",
    "    \n",
    "    x_member = x_train[:batch_size]\n",
    "    y_member = y_train[:batch_size]\n",
    "    x_nonmember = x_test[:400]\n",
    "    y_nonmember = y_test[:400]\n",
    "\n",
    "    x_target = np.concatenate([x_member, x_nonmember], axis=0)\n",
    "    y_target = np.concatenate([y_member, y_nonmember], axis=0)\n",
    "    \n",
    "    x_tensor = torch.from_numpy(x_target).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_tensor)\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        max_confidence = prob.max(dim=1).values.cpu().numpy()\n",
    "        \n",
    "    mia_pred = (max_confidence > threshold).astype(np.int32)\n",
    "    true_membership = np.array([1] * batch_size + [0] * 400)\n",
    "    \n",
    "    MIA_ACC = (mia_pred == true_membership).mean()\n",
    "        \n",
    "    return MIA_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "0b83d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7383333333333333\n"
     ]
    }
   ],
   "source": [
    "MIA_ACC = Conf_Rule_based_Attack(distilled)\n",
    "print(MIA_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "cc2c48ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6725\n"
     ]
    }
   ],
   "source": [
    "MIA_ACC = Conf_Rule_based_Attack(synthetic)\n",
    "print(MIA_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "4c0d74d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6092857142857143\n"
     ]
    }
   ],
   "source": [
    "MIA_ACC = Conf_Rule_based_Attack(adv_synthetic)\n",
    "print(MIA_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "d73e76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_logits_non_loader(model, data):\n",
    "    '''\n",
    "    x_tensor = torch.from_numpy(x_target).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_tensor)\n",
    "        pred_labels = logits.argmax(dim=1).cpu().numpy()\n",
    "    '''\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        return model(data)\n",
    "\n",
    "\n",
    "def train_attack_model(logits_in, logits_out):\n",
    "    probs_in = F.softmax(logits_in, dim=1).cpu().numpy()\n",
    "    probs_out = F.softmax(logits_out, dim=1).cpu().numpy()\n",
    "    \n",
    "    x = np.concatenate([probs_in, probs_out], axis=0)\n",
    "    y = np.concatenate([np.ones(len(probs_in)), np.zeros(len(probs_out))], axis=0)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8)\n",
    "    \n",
    "    attack_model = LogisticRegression(max_iter=5000)\n",
    "    # attack_model = RandomForestClassifier(n_estimators=150)\n",
    "    attack_model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = attack_model.predict(x_test)\n",
    "    y_score = attack_model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    MIA_ACC = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return MIA_ACC\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb3a02",
   "metadata": {},
   "source": [
    "> ### Logistic Classifier Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "dffa304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "dist_logits_in = collect_logits_non_loader(distilled, x_train)\n",
    "dist_logits_out = collect_logits_non_loader(distilled, x_test[:300])\n",
    "print(train_attack_model(dist_logits_in, dist_logits_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "3c46ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223214285714286\n"
     ]
    }
   ],
   "source": [
    "syn_logits_in = collect_logits_non_loader(synthetic, x_train)\n",
    "syn_logits_out = collect_logits_non_loader(synthetic, x_test[:400])\n",
    "print(train_attack_model(syn_logits_in, syn_logits_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "62711320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7035714285714286\n"
     ]
    }
   ],
   "source": [
    "adv_syn_logits_in = collect_logits_non_loader(adv_synthetic, x_train)\n",
    "adv_syn_logits_out = collect_logits_non_loader(adv_synthetic, x_test[:400])\n",
    "print(train_attack_model(adv_syn_logits_in, adv_syn_logits_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eeedde",
   "metadata": {},
   "source": [
    "> ### RandomForest Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "8009aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567307692307692\n",
      "0.7211538461538461\n",
      "0.6732142857142858\n"
     ]
    }
   ],
   "source": [
    "dist_logits_in = collect_logits_non_loader(distilled, x_train)\n",
    "dist_logits_out = collect_logits_non_loader(distilled, x_test[:300])\n",
    "print(train_attack_model(dist_logits_in, dist_logits_out))\n",
    "\n",
    "syn_logits_in = collect_logits_non_loader(synthetic, x_train)\n",
    "syn_logits_out = collect_logits_non_loader(synthetic, x_test[:300])\n",
    "print(train_attack_model(syn_logits_in, syn_logits_out))\n",
    "\n",
    "adv_syn_logits_in = collect_logits_non_loader(adv_synthetic, x_train)\n",
    "adv_syn_logits_out = collect_logits_non_loader(adv_synthetic, x_test[:400])\n",
    "print(train_attack_model(adv_syn_logits_in, adv_syn_logits_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "0710b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_only_decision_boundary(model, x_target, n_perturb=20, epsilon=0.1, threshold_ratio=0.2):\n",
    "    '''\n",
    "    n_perturb : perturbation 반복 횟수\n",
    "    epsilon : perturbation 강도\n",
    "    threshold_ratio : label 변화 허용 비율 (ex: 0.25 -> 20회 중 5회 이상 바뀌면 non-member)\n",
    "    '''\n",
    "    model.eval()\n",
    "    N = x_target.size(0)\n",
    "    x_target = x_target.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        pred_clean = model(x_target).argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "    boundary_score = np.zeros(N)\n",
    "    for t in range(n_perturb):\n",
    "        noise = (torch.rand_like(x_target) - 0.5) * 2 * epsilon\n",
    "        x_perturbed = torch.clamp(x_target + noise, 0, 1)\n",
    "        with torch.no_grad():\n",
    "            pred_noisy = model(x_perturbed).argmax(dim=1).cpu().numpy()\n",
    "        boundary_score += (pred_noisy != pred_clean)\n",
    "    \n",
    "    threshold = int(n_perturb * threshold_ratio)\n",
    "    inferred_membership = (boundary_score <= threshold).astype(np.int32)\n",
    "    return inferred_membership, boundary_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "6402d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-Only Decision Boundary MIA accuracy: 0.6433\n"
     ]
    }
   ],
   "source": [
    "x_all = torch.cat([x_train, x_test], dim=0)\n",
    "inferred_membership, boundary_score = label_only_decision_boundary(distilled, x_all)\n",
    "true_membership = np.array([1] * 1000 + [0] * 500)\n",
    "MIA_ACC = (inferred_membership == true_membership).mean()\n",
    "print(f\"Label-Only Decision Boundary MIA accuracy: {MIA_ACC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "443ef46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-Only Decision Boundary MIA accuracy: 0.5847\n"
     ]
    }
   ],
   "source": [
    "x_all = torch.cat([x_train, x_test], dim=0)\n",
    "inferred_membership, boundary_score = label_only_decision_boundary(synthetic, x_all)\n",
    "true_membership = np.array([1] * 1000 + [0] * 500)\n",
    "MIA_ACC = (inferred_membership == true_membership).mean()\n",
    "print(f\"Label-Only Decision Boundary MIA accuracy: {MIA_ACC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "f6ab637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-Only Decision Boundary MIA accuracy: 0.5973\n"
     ]
    }
   ],
   "source": [
    "x_all = torch.cat([x_train, x_test], dim=0)\n",
    "inferred_membership, boundary_score = label_only_decision_boundary(adv_synthetic, x_all)\n",
    "true_membership = np.array([1] * 1000 + [0] * 500)\n",
    "MIA_ACC = (inferred_membership == true_membership).mean()\n",
    "print(f\"Label-Only Decision Boundary MIA accuracy: {MIA_ACC:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
